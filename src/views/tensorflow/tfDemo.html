<html>
  <head>
    <!-- 这里加载官方的Tf.js库文件 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.11.7"> </script>
    <!-- 简单概念 张量 变量 操作 -->
    <!-- Place your code in the script tag below. You can also use an external .js file -->
    <script>
      //张量
      // 1阶张量
      tf.tensor1d([1, 2, 3]).print()
      // 2阶张量
      tf.tensor2d([1, 2, 3, 4], [2, 2]).print()
      // 3阶张量
      tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print()
      // 4阶张量
      tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]).print()
      //0或1
      tf.zeros([3,5]).print()
      tf.ones([2,4]).print()
      tf.onesLike([1,2,3,4]).ptint()//[1,1,1,1]
      tf.zerosLike([1,2,3,4]).ptint()//[1,1,1,1]

      //变量
      const initialValues = tf.zeros([5]);//[0,0,0,0,0]
      const biases = tf.variable(initialValues); // 初始化偏差（距离原点的截距或偏移）
      tf.variable(tf.randomNormal([3, 2])).print()//随机
      biases.assign(tf.tensor1d([1,3,5,7,9])) //更新数据
      biases.print();

      //操作
      /** 
       * data.square() 数学函数平方
       * data.sqrt() 数学函数开方
       * data.add() 运算函数
       * 所有操作可链式操作
      */
     const data=tf.tensor1d([1, 2, 3])
     data.add(tf.tensor1d([1,2,3])).add(tf.tensor1d([1,2,3])).print()

     //模型和层
      // 定义线性回归模型。2种实现形式
      let model
      if(true){
        model = tf.sequential();
        model.add(
          tf.layers.dense(
            {
              units: 1,
              inputShape: [1]//第一层必传
            }
          )
        );
      }else{
        model = tf.sequential({
          layers: [
            tf.layers.dense({inputShape: [784], units: 32, activation: 'relu'}),
            tf.layers.dense({units: 10, activation: 'softmax'}),
          ]
        })
      }
      // 为培训准备模型:指定损失和优化器。
      model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});//sgd优化器
      // 生成一些训练用的合成数据。
      const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);
      const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);
      // Train the model using the data.
      model.fit(xs, ys, {epochs: 10}).then(() => {
        // 使用模型对模型未见过的数据点进行推断:
        // 打开浏览器devtools查看输出
        model.predict(tf.tensor2d([5], [1, 1])).print();
      });
      //标量 scalar()
      tf.scalar(3).print()
      //缓冲区 buffer() 缓冲区方法 set() get() toTensor()
      tf.buffer([2,3]).toTensor().print()
      //克隆 clone()
      tf.tensor([2]).clone().print()
      //组合成复数 complex(实部,虚部)
      const real = tf.tensor1d([2.25, 3.25]);
      const imag = tf.tensor1d([4.75, 5.75]);
      // tf.complex(real, imag)//[2.25 + 4.75j , 3.25 + 5.75j]
      //返回复数的虚部 imag(复数) 返回实部 real(复数)
      //tf.imag(tf.complex(real, imag))//[4.75, 5.75]
      //tf.real(tf.complex(real, imag))//[-2.25, 3.25]

      //创建矩阵 eye(行数,列数,批处理形状[],类型)
      tf.eye(4,4,[2]).print()
      //填充值fill(形状[],值,类型?)
      tf.fill([2,2],5).print()
      //线性等分向量 linspace(start,end,num)始,末,份数
      tf.linspace(1,5,3).print()
      //幅度划分向量 range(start,end,step,dtype)
      tf.range(1,9,2).print()
      //独热 oneHot(指数,深度,匹配值,其余值)
      tf.oneHot(tf.tensor1d([1,3],'int32'),5,11,22).print()
      //打印 print(x,boolean)
      // tf.print(tf.tensor(1))||tf.tensor(1).print()

      /**
       * 截断正态分布随机数 truncatedNormal(shape,mean,stddev,dtype,seed,name)
       * 取值范围为 [ mean - 2 * stddev, mean + 2 * stddev ]
       * shape	是	1 维整形张量或 array	输出张量的维度
        mean	否	0 维张量或数值	均值
        stddev	否	0 维张量或数值	标准差
        dtype	否	dtype	输出类型
        seed	否	数值	随机种子，若 seed 赋值，每次产生相同随机数
        name	否	string	运算名称
      */
      tf.truncatedNormal([3,4],4,2,'int32').print()//0-8随机数

      /**
        * print()同级 张量的方法
        * buffer()
        * array()返回数组
        * data()
        * disponse()
        * clone()
        * toString()
        * ...
      */
      console.log(tf.tensor1d([1,2,3]).toString())
    </script>
  </head>

  <body>张量API-1</body>
</html>